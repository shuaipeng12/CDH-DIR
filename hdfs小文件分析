随着Hadoop集群数据量的增长，集群中也同时会存在大量的小文件，即文件Size比HDFS的Block Size（默认128MB）小的多的文件。Hadoop集群中存在大量的小文件对集群造成的影响如下：

1.对NameNode的内存造成很大的压力以及性能问题，在HDFS中任何文件、目录或者block在NameNode内存中均以对象的方式表示（即元数据），默认每个元数据对象约占150bytes。

2.HDFS在存储小文件上效率会很低，同样在读取上也会导致大量的查找，在各个DN节点去检索小文件。

本篇文章主要基于HDFS提供的oiv命令来进行FsImage离线分析，将FsImage文件解析问指定的csv格式数据，如下是具体步骤。


https://mp.weixin.qq.com/s?__biz=MzI4OTY3MTUyNg==&mid=2247493966&idx=1&sn=dd02b485d7037fcddb56d93b212e555c&chksm=ec293947db5eb0516112d725c33f1339de7c1d0d45b76d6fb11f9defe3f4e71fd2fbb876d3d4&scene=21#wechat_redirect

https://mp.weixin.qq.com/s?__biz=MzI4OTY3MTUyNg==&mid=2247492796&idx=1&sn=5e15a9060f234d24c1fb112d9158970c&chksm=ec2934b5db5ebda381ced8a99e0170229e57c0692a03d73a087853f99a09a3ee9d4e83d57267&scene=21#wechat_redirect


	1. 从NN获取FSimage文件
	kinit hdfs
	mkdir -p /root/hdfs_Analyse
	hdfs dfsadmin -fetchImage /root/hdfs_Analyse/

	2. 使用hdfs oiv命令解析FSimage二进制文件
	hdfs oiv -p Delimited -delimiter '|' -t /tmp/fsimage.tmp -i  /root/hdfs_Analyse/fsimage_0000000000001367086 -o /root/hdfs_Analyse/fsimage.out    //指定分隔符为 ' | '

	3. 上传文件到hdfs
	hdfs dfs -mkdir -p  /hdfs_Analyse/fsimage_txt
	hdfs dfs -put /root/hdfs_Analyse/fsimage.out /hdfs_Analyse/fsimage_txt

	4. 创建外部表加载前面上传的fsimage.out文件
	CREATE EXTERNAL TABLE if not exists `fsimage_txt`(
	`path` string,
	`repl` int,
	`mdate` date,
	`atime` date,
	`pblksize` int,
	`blkcnt` bigint,
	`fsize` bigint,
	`nsquota` bigint,
	`dsquota` bigint,
	`permi` varchar(100),
	`usrname` varchar(100),
	`grpname` varchar(100))
	ROW FORMAT DELIMITED
	FIELDS TERMINATED BY '|'
	STORED AS TEXTFILE
	LOCATION '/hdfs_Analyse/fsimage_txt';    //通过location直接加载

	5. 创建内部表用于存储查询结果
	CREATE TABLE if not exists `file_info`(
	`path` string,
	`fsize` bigint,
	`usrname` varchar(100),
	`depth` int,
	`table_type` varchar(100),
	`db_name` varchar(100))
	STORED AS ORC;

	6. 对外部表 'fsimage_txt' 进行查询，分别对目录深度（depth）为（1，2，3，4，5，6）的文件查询结果插入内部表 'file_info'
	INSERT INTO TABLE file_info 
	  select concat('/' , split(`path`,'/')[1] , '/') as path1, fsize ,usrname, 1,split(`path`,'/')[3],split(`path`,'/')[5] 
	  from fsimage_txt;
	
	INSERT INTO TABLE file_info 
	  select concat('/' , split(`path`,'/')[1] , '/' , split(`path`,'/')[2] , '/') as path1, fsize ,usrname, 2,split(`path`,'/')[3],
	  split(`path`,'/')[5] 
	  from fsimage_txt;

	
	INSERT INTO TABLE file_info 
	  select concat('/' , split(`path`,'/')[1] , '/' , split(`path`,'/')[2] , '/', split(`path`,'/')[3] , '/') as path1, fsize ,usrname, 3,
	  split(`path`,'/')[3],split(`path`,'/')[5] 
	  from fsimage_txt;


	INSERT INTO TABLE file_info 
	  select concat('/' , split(`path`,'/')[1] , '/' , split(`path`,'/')[2] , '/', split(`path`,'/')[3] , '/', split(`path`,'/')[4] , '/') as path1, fsize ,usrname, 4,split(`path`,'/')[3],split(`path`,'/')[5] 
	  from fsimage_txt;


	INSERT INTO TABLE file_info 
	  select concat('/' , split(`path`,'/')[1] , '/' , split(`path`,'/')[2] , '/', split(`path`,'/')[3] , '/', split(`path`,'/')[4] , '/', split(`path`,'/')[5] , '/') as path1, fsize ,usrname, 5,split(`path`,'/')[3],split(`path`,'/')[5] 
	  from fsimage_txt;


	INSERT INTO TABLE file_info 
	  select concat('/' , split(`path`,'/')[1] , '/' , split(`path`,'/')[2] , '/', split(`path`,'/')[3] , '/', split(`path`,'/')[4] , '/', split(`path`,'/')[5] , '/' ,split(`path`,'/')[6] , '/') as path1, fsize ,usrname, 6,split(`path`,'/')[3],split(`path`,'/')[5] 
	  from fsimage_txt;

	
	7. 对file_info表进行查询，统计小文件信息
	-- 对外部表‘file_info’ 进行查询，分别对目录深度（depth）为（1，2，3，4，5，6）的小文件数量进行统计，可以看到主要是 /user/hive/warehouse 贡献了小文件。
	select path, count(1) as cnt from file_info where fsize <= 30000000 and path like '/warehouse/tablespace/%' and depth = 3 group by path order by cnt desc limit 20; 
	
	-- 对外部表‘file_info’ 进行查询，分别对目录深度（depth）为（1，2，3，4，5，6）的小文件数量进行统计，可以看到主要是 /user/hive/warehouse/xxx.db 贡献了小文件。
	select path, count(1) as cnt from file_info where fsize <= 30000000 and path like '/warehouse/tablespace/managed/hive/%' and depth = 5 group by path order by cnt desc limit 20; 
	
	-- 对外部表‘file_info’ 进行查询，分别对目录深度（depth）为（1，2，3，4，5，6）的小文件数量进行统计，可以看到主要是 /user/hive/warehouse/xxx.db 贡献了小文件。
	select path, count(1) as cnt from file_info where fsize <= 30000000 and path like '/warehouse/tablespace/external/hive/%' and depth = 5 group by path order by cnt desc limit 20; 
	
	-- 对外部表‘file_info’ 进行查询，分别对目录深度（depth）为（1，2，3，4，5，6）的小文件数量进行统计，可以看到主要是 /user/hive/warehouse/xxx.db 贡献了小文件。
	set hive.tez.container.size = 8192;
	select `path`, count(1) as cnt from file_info 
	where fsize <= 30000000 
	and db_name='tdjd_mof.db'
	and table_type='managed'
	and depth = 6 
	and `path` is not null
	group by `path` 
	order by cnt desc  
	limit 20; 
	
	-- 对外部表‘file_info’ 进行查询，分别对目录深度（depth）为（1，2，3，4，5，6）的小文件数量进行统计，可以看到主要是 /user/hive/warehouse/xxx.db 贡献了小文件。
	set hive.tez.container.size = 8192;
	select `path`, count(1) as cnt from file_info 
	where fsize <= 30000000 
	and db_name='tdjd_mof.db'
	and table_type='external'
	and depth = 6 
	and `path` is not null
	group by `path` 
	order by cnt desc  
	limit 40; 
	
	set hive.tez.container.size = 8192;
	select `path`, count(1) as cnt from file_info 
	where fsize <= 30000000 
	and db_name='dip_public.db'
	and table_type='external'
	and depth = 6 
	and `path` is not null
	group by `path` 
	order by cnt desc  
	limit 20; 
	
	set hive.tez.container.size = 8192;
	select `path`, count(1) as cnt from file_info 
	where fsize <= 30000000 
	and db_name='dccdm.db'
	and table_type='external'
	and depth = 6 
	and `path` is not null
	group by `path` 
	order by cnt desc  
	limit 20; 

	统计小文件信息是从根目录下一层层的查下去的
	小文件的大小是自己定义的，这里定义的是小于30M的为小文件，可以定义成其他大小。
